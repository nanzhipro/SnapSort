# SnapSort 开发日志汇总

----
时间：2025-05-20
地点：书房
关键记录：

- ScreenshotMonitor运行在命令行下，是可以完好工作的。可以放在App中，就无法监听文件变化。是工作线程问题还是权限问题？

----

----
时间：2025-05-18
地点：车里等儿子篮球课下课
关键记录：

- Cursor也好，或者其他AI Coding也好，有时候不是越多的上下文越好。准确说，应该是越精准的上下文越好。如果输入过多的上下文，那语言的表达就需要更加精准。一旦不够精准，AI就会输出很多意外的代码或者结构。
- 这里有一个好办法，可以把组件或者模块单独来设计，组件可复用，可独立编译，可以独立测试和运行。把模块当成一个开源SDK，提供精准的API能力调用，提供精准的输入和输出参数定义。

----

----
时间：2025-05-17
地点：书房
关键记录：

- 前期的很多文档约定，在项目进行中，能删除的就要删除掉，也需要随着项目进行的过程中，修改文档。
避免造成文档定义和实际项目不一致的情况。如果不一致，AI也很难办。
- 相较于开发ScheduleSage，开发SnapSort我更注重开发过程的设计。如准备更充分的文档，更精准地编排技术需求，限定更严格的边界
让AI不至于变成脱缰的野马，而是被驯服和训练有素的战马。

----

----
时间：2025-05-16
地点：书房
关键记录：

- 0.50版本的Cursor终于可以导出聊天记录了，这样就可以记录自己如何与AI来写作。
- 文档准备差不多了，可以进入实际的编码阶段了。

----

----
时间：2025-05-15
地点：书房
关键记录：

- Context7平台：<https://context7.com/>
  <https://github.com/upstash/context7>

  把github仓库文档化，再通过MCP Server访问。起到把github内容，输入给LLMs的目的。
  如，在SnapSort项目中，需要调用DeepSeek API。DS提供了OpenAI相同的调用方式，其确保低代码迁移成本。
  同样代码，既可以接入DeepSeek，也可以接入ChatGPT，还可以其他，如腾讯混元。

  这里SnapSort选择： <https://github.com/MacPaw/OpenAI>
  利用Context7平台，就可以输入MacPaw/OpenAI，使其文档化。
  <https://context7.com/add-library?tab=github&library=%2Fmacpaw%2Fopenai>

- 文档化成为了LLMs或者AI Coding的核心。定义清晰，内容详实的文档，可以更好的利用AI的超强能力。
  给出的文档越是详细，边界定义越是清晰，AI越能给出确定性的代码。

  在传统的团队软件开发模式中，为了追求代码的一致性，我们会约定编码规范，文档规范，设计规范。
  这些内容，在目前这个AI软件开发方式下，依然试用，而且会更强烈。

- firecrawl平台
  <https://www.firecrawl.dev/app/playground>

  这个平台也是一个非常好的文档化的平台。
  比如，SnapSort需要调用DeepSeekAPI。我们找到DeepSeek API官网： <https://api-docs.deepseek.com/zh-cn/>

  把这个URL输入到firecrawl playground中，就会吐出完整的解析后的markdown文档。
  在输入给Curosr，以下就是输出的内容。

---------
[跳到主要内容](https://api-docs.deepseek.com/zh-cn/#__docusaurus_skipToContent_fallback)

本页总览

# 首次调用 API

DeepSeek API 使用与 OpenAI 兼容的 API 格式，通过修改配置，您可以使用 OpenAI SDK 来访问 DeepSeek API，或使用与 OpenAI API 兼容的软件。

| PARAM | VALUE |
| --- | --- |
| base\_url \* | `https://api.deepseek.com` |
| api\_key | apply for an [API key](https://platform.deepseek.com/api_keys) |

\\* 出于与 OpenAI 兼容考虑，您也可以将 `base_url` 设置为 `https://api.deepseek.com/v1` 来使用，但注意，此处 `v1` 与模型版本无关。

\\* **`deepseek-chat` 模型已全面升级为 DeepSeek-V3，接口不变。** 通过指定 `model='deepseek-chat'` 即可调用 DeepSeek-V3。

\\* **`deepseek-reasoner` 是 DeepSeek 最新推出的 [推理模型](https://api-docs.deepseek.com/zh-cn/guides/reasoning_model) DeepSeek-R1**。通过指定 `model='deepseek-reasoner'`，即可调用 DeepSeek-R1。

## 调用对话 API [​](https://api-docs.deepseek.com/zh-cn/\#%E8%B0%83%E7%94%A8%E5%AF%B9%E8%AF%9D-api "调用对话 API的直接链接")

在创建 API key 之后，你可以使用以下样例脚本的来访问 DeepSeek API。样例为非流式输出，您可以将 stream 设置为 true 来使用流式输出。

- curl
- python
- nodejs

```codeBlockLines_UUn8
curl https://api.deepseek.com/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer <DeepSeek API Key>" \
  -d '{
        "model": "deepseek-chat",
        "messages": [\
          {"role": "system", "content": "You are a helpful assistant."},\
          {"role": "user", "content": "Hello!"}\
        ],
        "stream": false
      }'

```

```codeBlockLines_UUn8
# Please install OpenAI SDK first: `pip3 install openai`

from openai import OpenAI

client = OpenAI(api_key="<DeepSeek API Key>", base_url="https://api.deepseek.com")

response = client.chat.completions.create(
    model="deepseek-chat",
    messages=[\
        {"role": "system", "content": "You are a helpful assistant"},\
        {"role": "user", "content": "Hello"},\
    ],
    stream=False
)

print(response.choices[0].message.content)

```

```codeBlockLines_UUn8
// Please install OpenAI SDK first: `npm install openai`

import OpenAI from "openai";

const openai = new OpenAI({
        baseURL: 'https://api.deepseek.com',
        apiKey: '<DeepSeek API Key>'
});

async function main() {
  const completion = await openai.chat.completions.create({
    messages: [{ role: "system", content: "You are a helpful assistant." }],
    model: "deepseek-chat",
  });

  console.log(completion.choices[0].message.content);
}

main();

```

- [调用对话 API](https://api-docs.deepseek.com/zh-cn/#%E8%B0%83%E7%94%A8%E5%AF%B9%E8%AF%9D-api)

----

----
时间：2025-05-13
地点：书房
关键记录：

1. 暂时不考虑包含敏感信息的截图，只做文本分类。
2. 在开发ScheduleSage的时候，期望使用提示词来约束LLMs给出JSON输出，细看文档，发现其实包括OpenAI，DeepSeek在内的LLMs已经可以使用调用参数来约束JSON输出格式了。
response = client.chat.completions.create(
    model="deepseek-chat",
    messages=messages,
    response_format={
        'type': 'json_object'
    }
)
3.把API文档markdown化，使用：<https://www.firecrawl.dev/>
4.SnapSort本地存储技术选型
本地存储没有复杂的存储类型和数据，数据模型是以图片文件为关键Key的。

--
Table字段：
ImageFilePath, Classfication, FullText

看起来使用SQLite就行，简单文档，结构化良好。
SwiftData虽然高级，但并非AI擅长的，2023年的框架，AI能学到的也不多。

5.应用流程文档（流程图+时序图）：与Cursor AI协作的最佳语言
<https://mp.weixin.qq.com/s/FAfNHUsr8_sW9P7Z1jWHzA>
----

----
时间：2025-05-12
地点：书房
关键记录：

1. 今天需要基于给定的产品PRD设定，来逐步完善技术分析，技术调研，形成更多细节的技术方案。尤其是需要更多的文档参考，代码示例，API调用示例等等，给AI更多有效的上下文。
2. 今天需要单独使用AI直接写一些demo来验证几个关键模块，比如 NSMetadataQuery，敏感信息检测（SensitiveInfoDetector）其他模块，都是标准模块，做好技术边界的设计就好
3.ScreenshotMonitor 组件demo运行良好。

> ➜  ScreenshotMonitor git:(main) ✗ .build/arm64-apple-macosx/debug/ScreenshotMonitorCLI
> ScreenshotMonitor 已启动
>2025-05-12 08:49:13 - 检测到新截图: /Users/nanzhi/Desktop/截屏2025-05-12 08.49.06.png
>2025-05-12 08:49:14 - 检测到新截图: /Users/nanzhi/Desktop/截屏2025-05-12 08.49.06 (2).png
>2025-05-12 08:49:31 - 检测到新截图: /Users/nanzhi/Desktop/截屏2025-05-12 08.49.28.png
----

----
时间：2025-05-11
地点：在车里等儿子上篮球课下课
关键记录：

## 日常思考

1. PRD基本确立之后，大概的产品功能需求也就确定下来了。
接下来，就需要专门针对不同模块开始技术调研。
术方案需要形成详细的技术markdown文档，作为AI的上线文。
2.每周形成一份开发报告，输出发布小红书。
3.果断放弃传统的研发模式，如瀑布开发模型，敏捷开发模式。这些模式在AI时代，似乎并不匹配。AI研发，是一个设定好边界后，不断尝试的过程。快速让AI输出结果，马上验证，符合预期就保留，不符合预期就废弃。代码已经不是什么辛辛苦苦誊写，撰写出来的辛苦成果物，而是即时获得的内容。在过往的开发模式中，删除已经写好的代码，是一种负担，甚至制造一起冲突，如需求变更，甚至对bug的认定，都会形成冲突。因为这意味着劳动成果需要推翻重来。但是AI不存在这个冲突，完美解决了。不符合预期是嘛，那容我整理一下思路，重新提问一次。
4.如果开发一款App，那是不是什么事情都可以交给AI来做。答案是的，如果是数字化的内容，都完全可以交给AI来完成。人类在中间做的事情，就是操作，打通流程，做好协调者的角色。这次的挑战目标就是： 如果AI能做，我就不做，我只做确认。
5.让我们来挑战第一个本来由人来来完成，反而要交给AI来做的事情，就是App的模块划分和架构设计。
6. 需要进一步完善和细化PRD，然后根据细化的产品PRD，形成一份详细的技术PRD（产品PRD的技术上，增加所有的技术细节）。两份文档够用了。一份给人看，一份给AI看。
7. 根据产品PRD，让grok深度调研，输出一份技术prd的初稿，然后我再来审核并完善其中的更多细节。

## 今日灵感
>
> 使用Gemini-2.5-pro-exp模型，来辅助我们思考，来完善想法和方案。仿佛他就是一个资深顾问，在我们的对面，我们随时沟通，随时提问，随时给出反馈。
> 借助AI，把我头脑中零散的想法，系统化，结构化。
> 我需要花更多的时间来完善文档，文档中需要明确表达出产品需求和技术方案细节，包括技术参考，相关示例代码
----
